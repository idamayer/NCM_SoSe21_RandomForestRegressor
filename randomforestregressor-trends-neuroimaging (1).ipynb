{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-06-25T20:28:50.218317Z","iopub.execute_input":"2021-06-25T20:28:50.218631Z","iopub.status.idle":"2021-06-25T20:28:50.224844Z","shell.execute_reply.started":"2021-06-25T20:28:50.218602Z","shell.execute_reply":"2021-06-25T20:28:50.223642Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# these are the independent variables\ndf = pd.read_csv(\"../input/trends-assessment-prediction/loading.csv\")\nfeatures = list(df.columns[1:])\n\n# these are the dependent variables\nlabels_df = pd.read_csv(\"../input/trends-assessment-prediction/train_scores.csv\")\n\ndf = df.merge(labels_df, on=\"Id\", how=\"left\")\ndf.dropna()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T20:28:50.232795Z","iopub.execute_input":"2021-06-25T20:28:50.233153Z","iopub.status.idle":"2021-06-25T20:28:50.382414Z","shell.execute_reply.started":"2021-06-25T20:28:50.233122Z","shell.execute_reply":"2021-06-25T20:28:50.381264Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"          Id     IC_01     IC_07     IC_05     IC_16     IC_26     IC_06  \\\n0      10001  0.006070  0.014466  0.004136  0.000658 -0.002742  0.005033   \n1      10002  0.009087  0.009291  0.007049 -0.002076 -0.002227  0.004605   \n3      10004  0.004675  0.000957  0.006154 -0.000429 -0.001222  0.011755   \n6      10007  0.005192  0.010585  0.012160 -0.000920 -0.002255  0.011416   \n7      10008  0.007745  0.009748  0.009356 -0.004219 -0.003852  0.012024   \n...      ...       ...       ...       ...       ...       ...       ...   \n11745  21746 -0.001115  0.007108  0.008652  0.003596  0.000950  0.016314   \n11746  21747  0.007263  0.016489  0.012704  0.004357 -0.005044  0.013909   \n11749  21750  0.005996  0.003873  0.012353  0.000242 -0.002159  0.020201   \n11751  21752  0.000627  0.011407  0.010957  0.000534 -0.000347  0.013499   \n11753  21754  0.010670  0.010670  0.006662 -0.002215 -0.001773  0.006544   \n\n          IC_10     IC_09     IC_18  ...     IC_20     IC_30     IC_22  \\\n0      0.016720  0.003484  0.001797  ...  0.010496  0.002892 -0.023235   \n1      0.012277  0.002946  0.004086  ...  0.005739  0.002880 -0.016609   \n3      0.013010  0.000193  0.008075  ... -0.000319  0.005866 -0.015182   \n6      0.013838  0.001929  0.003051  ...  0.003731  0.000733 -0.008462   \n7      0.010205  0.002903  0.000870  ...  0.004483  0.000688 -0.013822   \n...         ...       ...       ...  ...       ...       ...       ...   \n11745  0.017090  0.003513  0.004217  ...  0.006943  0.003312 -0.011562   \n11746  0.019284 -0.006267 -0.000456  ...  0.001316  0.003792 -0.022357   \n11749  0.020931  0.003684 -0.002458  ...  0.004942  0.007751 -0.020226   \n11751  0.010541  0.001867  0.007447  ...  0.002026  0.001876 -0.014612   \n11753  0.010900  0.000563  0.002995  ...  0.002420  0.003115 -0.020373   \n\n          IC_29     IC_14        age  domain1_var1  domain1_var2  \\\n0      0.022177  0.017192  57.436077     30.571975     62.553736   \n1      0.025543  0.014524  59.580851     50.969456     67.470628   \n3      0.024476  0.014760  71.413018     53.152498     58.012103   \n6      0.026733  0.014358  38.617381     49.197021     65.674285   \n7      0.029328  0.010936  35.326582     15.769168     65.782269   \n...         ...       ...        ...           ...           ...   \n11745  0.032932  0.011053  14.257265     21.358872     61.165998   \n11746  0.031624  0.016982  55.456978     68.169675     29.907995   \n11749  0.028821  0.017492  48.948756     55.114811     60.878271   \n11751  0.021665  0.019592  66.532630     59.844808     72.303110   \n11753  0.023804  0.012477  68.820928     56.594193     34.605868   \n\n       domain2_var1  domain2_var2  \n0         53.325130     51.427998  \n1         60.651856     58.311361  \n3         52.418389     62.536641  \n6         40.151376     34.096421  \n7         44.643805     50.448485  \n...             ...           ...  \n11745     51.778483     54.640179  \n11746     55.349257     54.019517  \n11749     38.617246     50.679885  \n11751     55.458281     46.870235  \n11753     49.922535     50.383078  \n\n[5434 rows x 32 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>IC_01</th>\n      <th>IC_07</th>\n      <th>IC_05</th>\n      <th>IC_16</th>\n      <th>IC_26</th>\n      <th>IC_06</th>\n      <th>IC_10</th>\n      <th>IC_09</th>\n      <th>IC_18</th>\n      <th>...</th>\n      <th>IC_20</th>\n      <th>IC_30</th>\n      <th>IC_22</th>\n      <th>IC_29</th>\n      <th>IC_14</th>\n      <th>age</th>\n      <th>domain1_var1</th>\n      <th>domain1_var2</th>\n      <th>domain2_var1</th>\n      <th>domain2_var2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10001</td>\n      <td>0.006070</td>\n      <td>0.014466</td>\n      <td>0.004136</td>\n      <td>0.000658</td>\n      <td>-0.002742</td>\n      <td>0.005033</td>\n      <td>0.016720</td>\n      <td>0.003484</td>\n      <td>0.001797</td>\n      <td>...</td>\n      <td>0.010496</td>\n      <td>0.002892</td>\n      <td>-0.023235</td>\n      <td>0.022177</td>\n      <td>0.017192</td>\n      <td>57.436077</td>\n      <td>30.571975</td>\n      <td>62.553736</td>\n      <td>53.325130</td>\n      <td>51.427998</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10002</td>\n      <td>0.009087</td>\n      <td>0.009291</td>\n      <td>0.007049</td>\n      <td>-0.002076</td>\n      <td>-0.002227</td>\n      <td>0.004605</td>\n      <td>0.012277</td>\n      <td>0.002946</td>\n      <td>0.004086</td>\n      <td>...</td>\n      <td>0.005739</td>\n      <td>0.002880</td>\n      <td>-0.016609</td>\n      <td>0.025543</td>\n      <td>0.014524</td>\n      <td>59.580851</td>\n      <td>50.969456</td>\n      <td>67.470628</td>\n      <td>60.651856</td>\n      <td>58.311361</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10004</td>\n      <td>0.004675</td>\n      <td>0.000957</td>\n      <td>0.006154</td>\n      <td>-0.000429</td>\n      <td>-0.001222</td>\n      <td>0.011755</td>\n      <td>0.013010</td>\n      <td>0.000193</td>\n      <td>0.008075</td>\n      <td>...</td>\n      <td>-0.000319</td>\n      <td>0.005866</td>\n      <td>-0.015182</td>\n      <td>0.024476</td>\n      <td>0.014760</td>\n      <td>71.413018</td>\n      <td>53.152498</td>\n      <td>58.012103</td>\n      <td>52.418389</td>\n      <td>62.536641</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>10007</td>\n      <td>0.005192</td>\n      <td>0.010585</td>\n      <td>0.012160</td>\n      <td>-0.000920</td>\n      <td>-0.002255</td>\n      <td>0.011416</td>\n      <td>0.013838</td>\n      <td>0.001929</td>\n      <td>0.003051</td>\n      <td>...</td>\n      <td>0.003731</td>\n      <td>0.000733</td>\n      <td>-0.008462</td>\n      <td>0.026733</td>\n      <td>0.014358</td>\n      <td>38.617381</td>\n      <td>49.197021</td>\n      <td>65.674285</td>\n      <td>40.151376</td>\n      <td>34.096421</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>10008</td>\n      <td>0.007745</td>\n      <td>0.009748</td>\n      <td>0.009356</td>\n      <td>-0.004219</td>\n      <td>-0.003852</td>\n      <td>0.012024</td>\n      <td>0.010205</td>\n      <td>0.002903</td>\n      <td>0.000870</td>\n      <td>...</td>\n      <td>0.004483</td>\n      <td>0.000688</td>\n      <td>-0.013822</td>\n      <td>0.029328</td>\n      <td>0.010936</td>\n      <td>35.326582</td>\n      <td>15.769168</td>\n      <td>65.782269</td>\n      <td>44.643805</td>\n      <td>50.448485</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11745</th>\n      <td>21746</td>\n      <td>-0.001115</td>\n      <td>0.007108</td>\n      <td>0.008652</td>\n      <td>0.003596</td>\n      <td>0.000950</td>\n      <td>0.016314</td>\n      <td>0.017090</td>\n      <td>0.003513</td>\n      <td>0.004217</td>\n      <td>...</td>\n      <td>0.006943</td>\n      <td>0.003312</td>\n      <td>-0.011562</td>\n      <td>0.032932</td>\n      <td>0.011053</td>\n      <td>14.257265</td>\n      <td>21.358872</td>\n      <td>61.165998</td>\n      <td>51.778483</td>\n      <td>54.640179</td>\n    </tr>\n    <tr>\n      <th>11746</th>\n      <td>21747</td>\n      <td>0.007263</td>\n      <td>0.016489</td>\n      <td>0.012704</td>\n      <td>0.004357</td>\n      <td>-0.005044</td>\n      <td>0.013909</td>\n      <td>0.019284</td>\n      <td>-0.006267</td>\n      <td>-0.000456</td>\n      <td>...</td>\n      <td>0.001316</td>\n      <td>0.003792</td>\n      <td>-0.022357</td>\n      <td>0.031624</td>\n      <td>0.016982</td>\n      <td>55.456978</td>\n      <td>68.169675</td>\n      <td>29.907995</td>\n      <td>55.349257</td>\n      <td>54.019517</td>\n    </tr>\n    <tr>\n      <th>11749</th>\n      <td>21750</td>\n      <td>0.005996</td>\n      <td>0.003873</td>\n      <td>0.012353</td>\n      <td>0.000242</td>\n      <td>-0.002159</td>\n      <td>0.020201</td>\n      <td>0.020931</td>\n      <td>0.003684</td>\n      <td>-0.002458</td>\n      <td>...</td>\n      <td>0.004942</td>\n      <td>0.007751</td>\n      <td>-0.020226</td>\n      <td>0.028821</td>\n      <td>0.017492</td>\n      <td>48.948756</td>\n      <td>55.114811</td>\n      <td>60.878271</td>\n      <td>38.617246</td>\n      <td>50.679885</td>\n    </tr>\n    <tr>\n      <th>11751</th>\n      <td>21752</td>\n      <td>0.000627</td>\n      <td>0.011407</td>\n      <td>0.010957</td>\n      <td>0.000534</td>\n      <td>-0.000347</td>\n      <td>0.013499</td>\n      <td>0.010541</td>\n      <td>0.001867</td>\n      <td>0.007447</td>\n      <td>...</td>\n      <td>0.002026</td>\n      <td>0.001876</td>\n      <td>-0.014612</td>\n      <td>0.021665</td>\n      <td>0.019592</td>\n      <td>66.532630</td>\n      <td>59.844808</td>\n      <td>72.303110</td>\n      <td>55.458281</td>\n      <td>46.870235</td>\n    </tr>\n    <tr>\n      <th>11753</th>\n      <td>21754</td>\n      <td>0.010670</td>\n      <td>0.010670</td>\n      <td>0.006662</td>\n      <td>-0.002215</td>\n      <td>-0.001773</td>\n      <td>0.006544</td>\n      <td>0.010900</td>\n      <td>0.000563</td>\n      <td>0.002995</td>\n      <td>...</td>\n      <td>0.002420</td>\n      <td>0.003115</td>\n      <td>-0.020373</td>\n      <td>0.023804</td>\n      <td>0.012477</td>\n      <td>68.820928</td>\n      <td>56.594193</td>\n      <td>34.605868</td>\n      <td>49.922535</td>\n      <td>50.383078</td>\n    </tr>\n  </tbody>\n</table>\n<p>5434 rows × 32 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# How a regression tree works: create a step function by learning the optimal boundary between steps\n# by minimizing sum of square residuals against every possible boundary in the data\n# then use the average value (or a linear regression?) for each step, to calculate the prediction of y\n# it's typical to truncate step splitting at steps of size <=20 to prevent overfitting\n\n# How a random forest works: a random forest is a collection of decision trees where the boundaries\n# are learned from only a randomly selected subset of k of the possible regressors  at each step,\n# on top of the bootstrapped data set. Then take an average of all the trees' predictions.\n\ntrain_df, test_df = train_test_split(df, test_size=0.33, shuffle=True)\n\n# Create the random forest regressor\n# a bootstrapped dataset is sample that was randomly sampled with replacement from some source dataset\nmodel = RandomForestRegressor(n_estimators=100, criterion=\"mse\", bootstrap = True)\nmodel.fit(train_df[features], train_df[\"age\"])\n\nprint(\"Accuracy score of Random Forest Regressor on age in training set\")\nprint(model.score(train_df[features], train_df[\"age\"]))\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T20:28:50.384673Z","iopub.execute_input":"2021-06-25T20:28:50.384944Z","iopub.status.idle":"2021-06-25T20:28:50.416889Z","shell.execute_reply.started":"2021-06-25T20:28:50.384909Z","shell.execute_reply":"2021-06-25T20:28:50.415052Z"},"trusted":true},"execution_count":55,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-55-3c5d906f4394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# a bootstrapped dataset is sample that was randomly sampled with replacement from some source dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mse\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy score of Random Forest Regressor on age in training set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."],"ename":"ValueError","evalue":"Input contains NaN, infinity or a value too large for dtype('float64').","output_type":"error"}]},{"cell_type":"code","source":"# Now we can create predictions and evaluate our model\n\ny_predicted = model.predict(test_df[features])\n\nprint(\"Accuracy score of Random Forest Regressor on predicting age in test set\")\nprint(model.score(test_df[features], test_df[\"age\"]))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T20:28:50.417997Z","iopub.status.idle":"2021-06-25T20:28:50.418450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# It would be nice to have a visual of how well we predicted ages, so convert our prediction to a\n# classification by decade of age, and plot of confusion matrix to show the accuracy of our prediction\ncm = confusion_matrix(test_df[\"age\"].round(-1).astype(int), y_predicted.round(-1).astype(int))\n\nplt.figure(figsize=(10,7))\nsns.heatmap(cm, annot=True, fmt = \"d\")\nplt.xlabel('Predicted (Age in decades)')\nplt.ylabel('Actual (Age in decades)')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T20:28:50.420100Z","iopub.status.idle":"2021-06-25T20:28:50.420532Z"},"trusted":true},"execution_count":null,"outputs":[]}]}